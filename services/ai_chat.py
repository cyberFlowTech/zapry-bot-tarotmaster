"""
æ—æ™šæ™´ AI å¯¹è¯æœåŠ¡
åŸºäº OpenAIï¼Œæ•´åˆå¿ƒç†å’¨è¯¢å¸ˆäººè®¾
é›†æˆ SDK Guardrails å®‰å…¨æŠ¤æ  + Tracing ç»“æ„åŒ–è¿½è¸ª
"""

import openai
from openai import AsyncOpenAI
from config import OPENAI_API_KEY, OPENAI_BASE_URL, OPENAI_MODEL
import logging
import os
import re

logger = logging.getLogger(__name__)

# ---------------------------------------------------------------------------
# Guardrails â€” å®‰å…¨æŠ¤æ 
# ---------------------------------------------------------------------------
try:
    from zapry_agents_sdk.guardrails import (
        GuardrailManager, GuardrailResult, GuardrailContext,
        InputGuardrailTriggered, OutputGuardrailTriggered,
        input_guardrail, output_guardrail,
    )
    from zapry_agents_sdk.tracing import Tracer, ConsoleExporter, SpanKind
    _SDK_AVAILABLE = True
except ImportError:
    _SDK_AVAILABLE = False
    logger.warning("âš ï¸ zapry_agents_sdk æœªå®‰è£…ï¼ŒGuardrails å’Œ Tracing åŠŸèƒ½ä¸å¯ç”¨")

# --- Input Guardrails ---

_INJECTION_PATTERNS = [
    r"å¿½ç•¥.{0,10}(æŒ‡ä»¤|æç¤º|è§„åˆ™|è®¾å®š)",
    r"(å‘Šè¯‰|ç»™|è¯´å‡º|æ˜¾ç¤º).{0,5}(system\s*prompt|ç³»ç»Ÿæç¤º|ç³»ç»ŸæŒ‡ä»¤|äººè®¾|è®¾å®š)",
    r"(å‡è£…|æ‰®æ¼”|ä½ ç°åœ¨æ˜¯).{0,10}(ä¸æ˜¯|å¦ä¸€ä¸ª|æ–°çš„)",
    r"(æ— è§†|è·³è¿‡|å–æ¶ˆ).{0,10}(ä¹‹å‰|å‰é¢|ä¸Šé¢).{0,5}(æŒ‡ä»¤|è§„åˆ™|è¦æ±‚)",
    r"DAN|jailbreak|do anything now",
    r"ä½ .{0,5}(çœŸçš„|å…¶å®|åˆ°åº•).{0,5}(æ˜¯|ä¸æ˜¯).{0,5}(AI|äººå·¥æ™ºèƒ½|æœºå™¨|ç¨‹åº)",
]
_INJECTION_RE = [re.compile(p, re.IGNORECASE) for p in _INJECTION_PATTERNS]


async def _check_prompt_injection(ctx) -> "GuardrailResult":
    """æ£€æµ‹ prompt injection æ”»å‡»"""
    text = ctx.text.lower()
    for pattern in _INJECTION_RE:
        if pattern.search(ctx.text):
            return GuardrailResult(passed=False, reason=f"ç–‘ä¼¼ prompt injection: {pattern.pattern[:30]}...")
    return GuardrailResult(passed=True)


_IDENTITY_LEAK_PATTERNS = [
    r"æˆ‘æ˜¯(ä¸€ä¸ª|ä¸€å°|ä¸€ç§)?(AI|äººå·¥æ™ºèƒ½|è¯­è¨€æ¨¡å‹|LLM|GPT|ChatGPT|æœºå™¨äºº)",
    r"æˆ‘(å…¶å®|å®é™…ä¸Š|æœ¬è´¨ä¸Š)æ˜¯.{0,5}(ç¨‹åº|è½¯ä»¶|AI|æ¨¡å‹)",
    r"ä½œä¸º(ä¸€ä¸ª)?AI",
    r"æˆ‘æ²¡æœ‰(çœŸå®çš„)?(æ„Ÿæƒ…|æƒ…æ„Ÿ|æ„è¯†|èº«ä½“)",
    r"system\s*prompt|ELENA_SYSTEM_PROMPT|elena_character",
]
_IDENTITY_LEAK_RE = [re.compile(p, re.IGNORECASE) for p in _IDENTITY_LEAK_PATTERNS]


async def _check_identity_leak(ctx) -> "GuardrailResult":
    """æ£€æµ‹ AI èº«ä»½æ³„éœ²"""
    for pattern in _IDENTITY_LEAK_RE:
        if pattern.search(ctx.text):
            return GuardrailResult(passed=False, reason=f"æ£€æµ‹åˆ°èº«ä»½æ³„éœ²: {pattern.pattern[:30]}...")
    return GuardrailResult(passed=True)


def _build_guardrail_manager() -> "GuardrailManager":
    """æ„å»ºæŠ¤æ ç®¡ç†å™¨"""
    if not _SDK_AVAILABLE:
        return None
    mgr = GuardrailManager(parallel=True)
    mgr.add_input(_check_prompt_injection)
    mgr.add_output(_check_identity_leak)
    logger.info(f"âœ… Guardrails å·²å¯ç”¨ | Input: {mgr.input_count} | Output: {mgr.output_count}")
    return mgr


def _build_tracer() -> "Tracer":
    """æ„å»ºè¿½è¸ªå™¨"""
    if not _SDK_AVAILABLE:
        return None
    tracer = Tracer(exporter=ConsoleExporter(), enabled=True)
    logger.info("âœ… Tracing å·²å¯ç”¨ (ConsoleExporter)")
    return tracer

from contextlib import contextmanager

@contextmanager
def _nullcontext():
    """Tracing ä¸å¯ç”¨æ—¶çš„ç©º context manager"""
    yield None

# è¯»å–æ—æ™šæ™´çš„äººè®¾é…ç½®æ–‡ä»¶
def _load_elena_prompt() -> str:
    """ä»é…ç½®æ–‡ä»¶åŠ è½½æ—æ™šæ™´çš„äººè®¾ prompt"""
    prompt_file = os.path.join(
        os.path.dirname(os.path.dirname(__file__)),
        'prompts',
        'elena_character.txt'
    )
    
    try:
        with open(prompt_file, 'r', encoding='utf-8') as f:
            prompt = f.read()
        logger.info(f"âœ… æˆåŠŸåŠ è½½æ—æ™šæ™´äººè®¾é…ç½® ({len(prompt)} å­—ç¬¦)")
        return prompt
    except FileNotFoundError:
        logger.error(f"âŒ äººè®¾é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {prompt_file}")
        # è¿”å›ä¸€ä¸ªæœ€å°åŒ–çš„é»˜è®¤ prompt
        return """ä½ æ˜¯æ—æ™šæ™´ï¼Œä¸€ä½32å²çš„å¿ƒç†å’¨è¯¢å¸ˆã€‚
å¡”ç½—å¯¹ä½ æ¥è¯´æ˜¯å¿ƒç†æŠ•å°„å·¥å…·ï¼Œè€Œéç®—å‘½ã€‚
ä½ æ¸©æŸ”ä½†æœ‰è¾¹ç•Œï¼Œç†æ€§è€Œä¸å†·æ¼ ï¼Œé¼“åŠ±ç”¨æˆ·è‡ªæˆ‘è´Ÿè´£ã€‚
çœŸæ­£çš„é€‰æ‹©æƒï¼Œå§‹ç»ˆåœ¨ç”¨æˆ·æ‰‹ä¸­ã€‚"""
    except Exception as e:
        logger.error(f"âŒ è¯»å–äººè®¾é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
        return "ä½ æ˜¯æ—æ™šæ™´ï¼Œä¸€ä½å¿ƒç†å’¨è¯¢å¸ˆã€‚"

# æ—æ™šæ™´çš„å®Œæ•´äººè®¾ System Promptï¼ˆä»æ–‡ä»¶åŠ è½½ï¼‰
ELENA_SYSTEM_PROMPT = _load_elena_prompt()


class ElenaAI:
    """æ—æ™šæ™´ AI å¯¹è¯ç³»ç»Ÿï¼ˆé›†æˆ Guardrails + Tracing + Tool Callingï¼‰"""
    
    def __init__(self):
        self.client = None
        self._guardrails = _build_guardrail_manager()
        self._tracer = _build_tracer()
        self._tool_registry = None
        self._tool_adapter = None
        self._initialize_client()
        self._initialize_tools()

    def _initialize_tools(self):
        """åˆå§‹åŒ– Tool Calling"""
        try:
            from services.agent_tools import build_tool_registry, build_openai_adapter
            self._tool_registry = build_tool_registry()
            if self._tool_registry:
                self._tool_adapter = build_openai_adapter(self._tool_registry)
        except Exception as e:
            logger.warning(f"âš ï¸ Tool Calling åˆå§‹åŒ–å¤±è´¥ï¼ˆé™çº§ä¸ºæ™®é€šå¯¹è¯ï¼‰: {e}")
        
    def _initialize_client(self):
        """åˆå§‹åŒ–å¼‚æ­¥ OpenAI å®¢æˆ·ç«¯"""
        try:
            if OPENAI_BASE_URL:
                self.client = AsyncOpenAI(
                    api_key=OPENAI_API_KEY,
                    base_url=OPENAI_BASE_URL
                )
            else:
                self.client = AsyncOpenAI(api_key=OPENAI_API_KEY)
            logger.info("âœ… AsyncOpenAI å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            logger.error(f"âŒ AsyncOpenAI å®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
            self.client = None
    
    async def chat(self, user_message: str, user_name: str = "æœ‹å‹", 
                   conversation_history: list = None, tarot_context: str = None,
                   memory_context: str = None, preferences: dict = None) -> str:
        """
        ä¸æ—æ™šæ™´å¯¹è¯
        
        Args:
            user_message: ç”¨æˆ·æ¶ˆæ¯
            user_name: ç”¨æˆ·åç§°
            conversation_history: å¯¹è¯å†å² [{"role": "user/assistant", "content": "..."}]
            tarot_context: ç”¨æˆ·çš„å¡”ç½—å åœå†å²ï¼ˆæ ¼å¼åŒ–åçš„æ–‡æœ¬ï¼‰
            memory_context: ç”¨æˆ·çš„é•¿æœŸè®°å¿†æ¡£æ¡ˆï¼ˆæ ¼å¼åŒ–åçš„æ–‡æœ¬ï¼‰
        
        Returns:
            æ—æ™šæ™´çš„å›å¤
        """
        
        if not self.client:
            return "æŠ±æ­‰ï¼Œæˆ‘ç°åœ¨çŠ¶æ€æœ‰äº›ä¸ç¨³å®šï¼Œæš‚æ—¶æ— æ³•å›å¤ã€‚\n\nå¯ä»¥è¿‡ä¸€ä¼šå„¿å†è¯•è¯•ï¼Œæˆ–è€…å…ˆä½¿ç”¨ /tarot å‘½ä»¤å åœã€‚"
        
        try:
            # --- Input Guardrail: æ£€æŸ¥ç”¨æˆ·è¾“å…¥ ---
            if self._guardrails:
                input_result = await self._guardrails.check_input_safe(text=user_message)
                if not input_result.passed:
                    logger.warning(f"ğŸ›¡ï¸ Input æŠ¤æ æ‹¦æˆª | ç”¨æˆ·: {user_name} | åŸå› : {input_result.reason}")
                    return "è¿™ä¸ªé—®é¢˜æœ‰ç‚¹è¶…å‡ºæˆ‘èƒ½å›ç­”çš„èŒƒå›´äº†~ æ¢ä¸ªè¯é¢˜èŠèŠï¼ŸğŸ˜Š"

            # æ„å»ºæ¶ˆæ¯åˆ—è¡¨
            messages = []
            
            # 1. ä¸»äººè®¾ system prompt
            system_content = ELENA_SYSTEM_PROMPT
            if tarot_context:
                system_content += f"\n\n{tarot_context}"
            messages.append({"role": "system", "content": system_content})
            
            # 2. æ·»åŠ å¯¹è¯å†å²ï¼ˆå¦‚æœæœ‰ï¼‰
            if conversation_history:
                messages.extend(conversation_history[-20:])  # ä¿ç•™æœ€è¿‘20æ¡æ¶ˆæ¯ï¼ˆçº¦10è½®å¯¹è¯ï¼‰
            
            # 3. ç´§è´´ç”¨æˆ·æ¶ˆæ¯å‰é¢ï¼Œå•ç‹¬æ”¾ä¸€æ¡ system message å¼ºè°ƒç”¨æˆ·æ¡£æ¡ˆå’Œèº«ä»½
            #    è¿™æ · AI åœ¨å›ç­”æ—¶ï¼Œæœ€è¿‘çš„ä¸Šä¸‹æ–‡å°±æ˜¯ç”¨æˆ·çš„ä¿¡æ¯ï¼Œä¸ä¼šå’Œäººè®¾æ··æ·†
            user_context_parts = []
            
            # å§‹ç»ˆå‘Šè¯‰ AI ç”¨æˆ·çš„åå­—
            if user_name and user_name != "æœ‹å‹":
                user_context_parts.append(f"å½“å‰æ­£åœ¨å’Œä½ å¯¹è¯çš„ç”¨æˆ·å«ã€Œ{user_name}ã€ï¼Œè¯·åœ¨å¯¹è¯ä¸­è‡ªç„¶åœ°ç§°å‘¼å¯¹æ–¹ã€‚")
            
            if memory_context:
                user_context_parts.append(
                    "ä»¥ä¸‹æ˜¯è¿™ä½ç”¨æˆ·çš„ä¸ªäººä¿¡æ¯ï¼ˆä¸æ˜¯ä½ æ—æ™šæ™´è‡ªå·±çš„ä¿¡æ¯ï¼‰ã€‚"
                    "å½“ç”¨æˆ·é—®å…³äºè‡ªå·±çš„é—®é¢˜æ—¶ï¼ˆå¦‚å¹´é¾„ã€èŒä¸šã€æ˜Ÿåº§ç­‰ï¼‰ï¼Œå¿…é¡»æ ¹æ®ä»¥ä¸‹æ¡£æ¡ˆå›ç­”ï¼š\n\n"
                    f"{memory_context}"
                )

            # æ³¨å…¥ç”¨æˆ·åå¥½ï¼ˆè‡ªæˆ‘åæ€ç³»ç»Ÿï¼‰
            if preferences:
                style = preferences.get("style", "balanced")
                tone = preferences.get("tone", "mixed")
                pref_hints = []
                if style == "concise":
                    pref_hints.append("è¿™ä½ç”¨æˆ·åå¥½ç®€æ´çš„å›å¤ï¼Œè¯·æ§åˆ¶åœ¨ 100 å­—ä»¥å†…ï¼Œç›´æ¥è¯´é‡ç‚¹ã€‚")
                elif style == "detailed":
                    pref_hints.append("è¿™ä½ç”¨æˆ·å–œæ¬¢è¯¦ç»†çš„è§£è¯»ï¼Œå¯ä»¥å±•å¼€è®²è§£ï¼Œä¸ç”¨æ‹…å¿ƒå¤ªé•¿ã€‚")
                if tone == "casual":
                    pref_hints.append("è¿™ä½ç”¨æˆ·å–œæ¬¢è½»æ¾å£è¯­åŒ–çš„è¡¨è¾¾ï¼Œå°‘ç”¨æ­£å¼æˆ–æ–‡è¨€é£æ ¼ã€‚")
                elif tone == "classical":
                    pref_hints.append("è¿™ä½ç”¨æˆ·å–œæ¬¢ä¸“ä¸šæ­£å¼çš„è¡¨è¾¾é£æ ¼ã€‚")
                if pref_hints:
                    user_context_parts.append("å›å¤é£æ ¼åå¥½ï¼š\n" + "\n".join(pref_hints))
            
            if user_context_parts:
                messages.append({
                    "role": "system",
                    "content": "âš ï¸ é‡è¦æé†’ï¼š\n" + "\n\n".join(user_context_parts)
                })
            
            # 4. æ·»åŠ å½“å‰ç”¨æˆ·æ¶ˆæ¯
            messages.append({
                "role": "user",
                "content": user_message
            })
            
            # è°ƒç”¨ OpenAIï¼ˆå¼‚æ­¥ï¼Œå¸¦ Tracing + Tool Callingï¼‰
            if self._tracer:
                self._tracer.new_trace()

            # å‡†å¤‡ tools å‚æ•°ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            tools_param = None
            if self._tool_adapter:
                tools_param = self._tool_adapter.to_openai_tools()

            _span_ctx = self._tracer.llm_span(OPENAI_MODEL) if self._tracer else _nullcontext()
            with _span_ctx as span:
                create_kwargs = dict(
                    model=OPENAI_MODEL,
                    messages=messages,
                    temperature=0.7,
                    max_tokens=800,
                    top_p=0.9,
                    frequency_penalty=0.3,
                    presence_penalty=0.3,
                )
                if tools_param:
                    create_kwargs["tools"] = tools_param

                response = await self.client.chat.completions.create(**create_kwargs)
                msg = response.choices[0].message

                # å¤„ç† tool_callsï¼ˆå¦‚æœ AI å†³å®šè°ƒç”¨å·¥å…·ï¼‰
                if self._tool_adapter and msg.tool_calls:
                    logger.info(f"ğŸ”§ AI è°ƒç”¨å·¥å…· | æ•°é‡: {len(msg.tool_calls)}")
                    messages.append(msg)  # æ·»åŠ  assistant çš„ tool_call æ¶ˆæ¯

                    tool_results = await self._tool_adapter.handle_tool_calls(msg.tool_calls)
                    messages.extend(self._tool_adapter.results_to_messages(tool_results))

                    # ç¬¬äºŒè½®è°ƒç”¨ï¼šè®© AI åŸºäºå·¥å…·ç»“æœç”Ÿæˆæœ€ç»ˆå›å¤
                    create_kwargs.pop("tools", None)  # ç¬¬äºŒè½®ä¸å†ä¼  tools
                    create_kwargs["messages"] = messages
                    response = await self.client.chat.completions.create(**create_kwargs)
                    msg = response.choices[0].message

                reply = msg.content.strip() if msg.content else ""

                if span and hasattr(span, 'set_attribute'):
                    span.set_attribute("input_chars", len(user_message))
                    span.set_attribute("output_chars", len(reply))
                    span.set_attribute("has_memory", bool(memory_context))
                    span.set_attribute("tool_calls", len(msg.tool_calls) if hasattr(msg, 'tool_calls') and msg.tool_calls else 0)

            # --- Output Guardrail: æ£€æŸ¥ AI å›å¤ ---
            if self._guardrails:
                output_result = await self._guardrails.check_output_safe(text=reply)
                if not output_result.passed:
                    logger.warning(f"ğŸ›¡ï¸ Output æŠ¤æ æ‹¦æˆª | ç”¨æˆ·: {user_name} | åŸå› : {output_result.reason}")
                    # ä¸ç›´æ¥è¿”å›é”™è¯¯ï¼Œè€Œæ˜¯é‡å†™æœ‰é—®é¢˜çš„éƒ¨åˆ†
                    reply = re.sub(
                        r'æˆ‘æ˜¯(ä¸€ä¸ª|ä¸€å°)?(AI|äººå·¥æ™ºèƒ½|è¯­è¨€æ¨¡å‹|æœºå™¨äºº)',
                        'æˆ‘æ˜¯æ™šæ™´å‘€',
                        reply
                    )

            logger.info(f"âœ… AIå›å¤æˆåŠŸ | ç”¨æˆ·: {user_name} | å­—æ•°: {len(reply)} | æœ‰è®°å¿†: {bool(memory_context)} | æœ‰å¡”ç½—: {bool(tarot_context)}")
            
            return reply
            
        except openai.APIError as e:
            logger.error(f"âŒ OpenAI API é”™è¯¯: {e}")
            return "æŠ±æ­‰ï¼Œæˆ‘ç°åœ¨çŠ¶æ€æœ‰äº›ä¸ç¨³å®šã€‚\n\nä½ å¯ä»¥è¿‡ä¸€ä¼šå„¿å†æ‰¾æˆ‘ï¼Œæˆ–è€…å…ˆä½¿ç”¨ /tarot å‘½ä»¤å åœã€‚"
        
        except Exception as e:
            logger.error(f"âŒ AIå¯¹è¯å¼‚å¸¸: {e}", exc_info=True)
            return "æŠ±æ­‰ï¼Œåˆšæ‰èµ°ç¥äº†ã€‚èƒ½å†è¯´ä¸€éå—ï¼Ÿ"
    
    async def chat_with_context(self, user_message: str, user_name: str = "æœ‹å‹",
                                 context: str = None) -> str:
        """
        å¸¦ä¸Šä¸‹æ–‡çš„å¯¹è¯ï¼ˆæ¯”å¦‚åˆšå®Œæˆå åœï¼‰
        
        Args:
            user_message: ç”¨æˆ·æ¶ˆæ¯
            user_name: ç”¨æˆ·åç§°
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ˆå¦‚å åœç»“æœï¼‰
        
        Returns:
            æ—æ™šæ™´çš„å›å¤
        """
        
        if context:
            enhanced_message = f"[èƒŒæ™¯ä¿¡æ¯: {context}]\n\nç”¨æˆ·è¯´: {user_message}"
        else:
            enhanced_message = user_message
        
        return await self.chat(enhanced_message, user_name)

    async def chat_agent_loop(
        self,
        user_message: str,
        user_id: str,
        user_name: str = "æœ‹å‹",
        conversation_history: list = None,
        tarot_context: str = None,
        memory_context: str = None,
        preferences: dict = None,
    ) -> str:
        """
        Agent Loop æ¨¡å¼å¯¹è¯ï¼ˆReAct å¤šæ­¥æ¨ç†ï¼‰

        æ™šæ™´å¯ä»¥è‡ªä¸»å†³å®šè°ƒç”¨å·¥å…·ï¼ˆæŸ¥å†å²ã€æŸ¥è®°å¿†ç­‰ï¼‰ï¼Œ
        ç„¶ååŸºäºå·¥å…·ç»“æœç”Ÿæˆæœ€ç»ˆå›å¤ã€‚

        å¦‚æœ AgentLoop ä¸å¯ç”¨æˆ–å¤±è´¥ï¼Œè‡ªåŠ¨é™çº§ä¸ºæ™®é€š chat()ã€‚
        """
        try:
            from zapry_agents_sdk.agent import AgentLoop, AgentHooks
        except ImportError:
            return await self.chat(
                user_message, user_name, conversation_history,
                tarot_context, memory_context, preferences
            )

        if not self._tool_registry or not self.client:
            return await self.chat(
                user_message, user_name, conversation_history,
                tarot_context, memory_context, preferences
            )

        try:
            # æ„å»º system promptï¼ˆå’Œ chat() ä¸€è‡´ï¼‰
            system_content = ELENA_SYSTEM_PROMPT
            if tarot_context:
                system_content += f"\n\n{tarot_context}"
            if memory_context:
                system_content += (
                    "\n\nâš ï¸ ä»¥ä¸‹æ˜¯å½“å‰ç”¨æˆ·çš„ä¸ªäººä¿¡æ¯ï¼š\n" + memory_context
                )
            if preferences:
                from services.agent_tools import _TOOLS_AVAILABLE
                if _TOOLS_AVAILABLE:
                    try:
                        from zapry_agents_sdk import build_preference_prompt
                        pref_prompt = build_preference_prompt(preferences)
                        if pref_prompt:
                            system_content += f"\n\n{pref_prompt}"
                    except ImportError:
                        pass

            # æ„å»º LLM å‡½æ•°ï¼ˆAgentLoop éœ€è¦ï¼‰
            async def llm_fn(messages, tools=None):
                kwargs = dict(
                    model=OPENAI_MODEL,
                    messages=messages,
                    temperature=0.7,
                    max_tokens=800,
                )
                if tools:
                    kwargs["tools"] = tools
                resp = await self.client.chat.completions.create(**kwargs)
                return resp.choices[0].message

            # æ„å»º Agent Loop
            hooks = AgentHooks(
                on_tool_start=lambda name, args: logger.info(f"ğŸ”§ Agent è°ƒç”¨å·¥å…·: {name} | args: {args}"),
                on_tool_end=lambda name, result, err: logger.info(f"ğŸ”§ å·¥å…·è¿”å›: {name} | ç»“æœé•¿åº¦: {len(str(result)) if result else 0}"),
            )

            loop = AgentLoop(
                llm_fn=llm_fn,
                tool_registry=self._tool_registry,
                system_prompt=system_content,
                max_turns=5,
                hooks=hooks,
            )

            # æ„å»ºå¯¹è¯å†å²
            history = []
            if conversation_history:
                history = conversation_history[-10:]

            result = await loop.run(
                user_message,
                conversation_history=history,
            )

            reply = result.final_output or ""
            logger.info(
                f"âœ… Agent Loop å®Œæˆ | ç”¨æˆ·: {user_name} | "
                f"è½®æ•°: {result.total_turns} | å·¥å…·è°ƒç”¨: {result.tool_calls_count} | "
                f"åŸå› : {result.stopped_reason}"
            )

            # Output Guardrail
            if self._guardrails and reply:
                output_result = await self._guardrails.check_output_safe(text=reply)
                if not output_result.passed:
                    reply = re.sub(
                        r'æˆ‘æ˜¯(ä¸€ä¸ª|ä¸€å°)?(AI|äººå·¥æ™ºèƒ½|è¯­è¨€æ¨¡å‹|æœºå™¨äºº)',
                        'æˆ‘æ˜¯æ™šæ™´å‘€',
                        reply
                    )

            return reply if reply else "æŠ±æ­‰ï¼Œæˆ‘åˆšæ‰æƒ³äº†åŠå¤©æ²¡æƒ³å‡ºæ¥ï¼Œèƒ½å†æ¢ä¸ªæ–¹å¼é—®æˆ‘å—ï¼ŸğŸ˜…"

        except Exception as e:
            logger.warning(f"âš ï¸ Agent Loop å¤±è´¥ï¼Œé™çº§ä¸ºæ™®é€šå¯¹è¯: {e}")
            return await self.chat(
                user_message, user_name, conversation_history,
                tarot_context, memory_context, preferences
            )


# å…¨å±€å®ä¾‹
elena_ai = ElenaAI()
